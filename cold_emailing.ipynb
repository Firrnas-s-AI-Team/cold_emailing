{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#  **Cold emailing**\n",
        "\n",
        "### **Introduction**\n",
        "\n",
        "This code implements an **Automated Cold Emailing System** designed for businesses to streamline their outreach process using AI-driven content generation and efficient email management workflows. The system integrates various components to handle the complete email lifecycle, from crafting personalized messages to managing responses and logging communication for future reference.\n",
        "\n",
        "### **Key Features:**\n",
        "1. **Automated Email Generation & Sending:**\n",
        "   - Leverages **Meta LLaMA-3.2-3B-Instruct** for generating customized email content tailored to specific company needs.\n",
        "   - Extracts relevant product information from a **PDF catalog** to enhance email personalization using **Retrieval-Augmented Generation (RAG)**.\n",
        "   - Sends emails via **SMTP (Gmail)** with attachments and stores sent emails in an **SQLite database** for easy tracking.\n",
        "\n",
        "2. **Response Management & Classification:**\n",
        "   - Periodically checks for incoming responses using **IMAP**, categorizing replies as:\n",
        "     - **Not Interested** (ignored)\n",
        "     - **Need More Details** (handled by querying the AI with product data)\n",
        "     - **Meeting Request** (forwarded to HR automatically)\n",
        "   - Uses **Qwen 2.5 model** with **4-bit quantization** for accurate response classification.\n",
        "\n",
        "3. **Product Recommendation System:**\n",
        "   - Utilizes **FAISS (Facebook AI Similarity Search)** and **Sentence Transformers** for efficient retrieval of relevant product suggestions based on customer needs.\n",
        "   - Embeds product descriptions to find the most relevant offerings in real time.\n",
        "\n",
        "4. **Database & Event-Driven Architecture:**\n",
        "   - **SQLite database** manages email logs (sent/received) with timestamp tracking.\n",
        "   - Event-driven logic ensures that responses are processed automatically without manual intervention.\n",
        "\n",
        "5. **Technologies & Libraries Used:**\n",
        "   - **Python Libraries:** `pandas`, `transformers`, `smtplib`, `PyPDF2`, `faiss`, `sqlite3`, `sentence-transformers`\n",
        "   - **AI Models:** Meta LLaMA, Qwen 2.5 for classification\n",
        "   - **Email Protocols:** SMTP (sending) & IMAP (receiving)\n",
        "   - **Database:** SQLite for email logging and tracking\n",
        "\n",
        "### **Usage Workflow:**\n",
        "1. Reads company information from a CSV file and product details from a PDF catalog.\n",
        "2. Generates personalized emails using AI, attaches relevant product details, and sends them via Gmail SMTP.\n",
        "3. Stores all sent and received emails in an SQLite database for future reference.\n",
        "4. Continuously monitors email responses, classifies them, and triggers the next action accordingly.\n"
      ],
      "metadata": {
        "id": "HpR-BA8-EGDG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ba99c5a"
      },
      "source": [
        "# installs the necessary Python libraries\n",
        "This cell installs the necessary Python libraries required for the cold emailing automation system. These packages include:\n",
        "\n",
        "* pandas: For data manipulation and analysis, especially with CSV files.\n",
        "\n",
        "* transformers: To work with pre-trained language models for generating email content.\n",
        "\n",
        "* smtplib: To send emails using the Simple Mail Transfer Protocol (SMTP).\n",
        "\n",
        "* PyPDF2: For extracting product information from PDF documents.\n",
        "\n",
        "* bitsandbytes: Optimizes model loading and quantization for efficient processing.\n",
        "\n",
        "* faiss-cpu: A library for efficient similarity search, useful for finding relevant products based on company needs.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFBkFBsTqIH2",
        "outputId": "d67ee17c-9f3c-4d00-e6e1-50a7a14ae69d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.2)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement smtplib (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for smtplib\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.45.2-py3-none-manylinux_2_24_x86_64.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.5.1+cu124)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.45.2-py3-none-manylinux_2_24_x86_64.whl (69.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bitsandbytes\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed PyPDF2-3.0.1 bitsandbytes-0.45.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.10.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas transformers smtplib\n",
        "!pip install PyPDF2 bitsandbytes\n",
        "!pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8af05ff"
      },
      "source": [
        "# logs into Hugging Face\n",
        "This cell logs into Hugging Face to authenticate and access pre-trained models from the Hugging Face Model Hub. This step is essential for generating high-quality email content using advanced language models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkd8YlJ4eF0E",
        "outputId": "e200c905-f57c-47df-c592-760d6b9456f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) y\n",
            "Token is valid (permission: fineGrained).\n",
            "The token `Cosmos` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
            "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
            "\n",
            "git config --global credential.helper store\n",
            "\n",
            "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
            "Token has not been saved to git credential helper.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `Cosmos`\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f110b7c"
      },
      "source": [
        "# script to sent first time\n",
        "This cell initializes the core functionalities of the cold emailing system, including:\n",
        "\n",
        "* Library Imports: Imports necessary modules for email handling, database management, NLP, and PDF processing.\n",
        "\n",
        "* SMTP Configuration: Configures the Gmail SMTP server to send emails securely.\n",
        "\n",
        "* Credentials Setup: Uses Gmail credentials (with an app password) for authentication.\n",
        "\n",
        "* Data Handling: Reads company details from a CSV file and extracts product information from a PDF catalog.\n",
        "\n",
        "* Database Initialization: Sets up an SQLite database to log sent and received emails.\n",
        "\n",
        "* Product Extraction: Extracts and organizes product details from the PDF.\n",
        "\n",
        "* Embedding & Similarity Search: Creates FAISS indexes to find relevant products based on company needs.\n",
        "\n",
        "* Email Generation: Uses an LLM to craft personalized emails with compelling subjects and content.\n",
        "\n",
        "* Email Sending: Sends customized emails to all companies listed in the CSV and logs them in the database.\n",
        "\n",
        "* Database Interaction: Includes functions to log, retrieve, and categorize emails for efficient tracking."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277,
          "referenced_widgets": [
            "19ce64eac55c4cfda31064513df52cf8",
            "a2394a35229646ad92e45becff0aec7b",
            "b9b2597e98d04cfab0c5e357c9d2c584",
            "46fa54e7ac80485bb7453b25c8460f43",
            "75d758fa70724ce6bfb912767179781b",
            "472405a3a9684085a3b66d1ca731bf72",
            "ca366d7080cd42189ef4df9135af637b",
            "bdf90ecc732a4ae5bc26c89eb821ad03",
            "0a7651e388e045e0ac5064ea94dbee74",
            "7e841da1420d4b86a71b0aa739d339fb",
            "44eaac4008ea4c6c89b71417d91e3b4d"
          ]
        },
        "id": "ldN2ehtn80R9",
        "outputId": "1f2d6271-35f0-411d-b492-5184ddb2b5ac"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "19ce64eac55c4cfda31064513df52cf8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'role': 'system', 'content': 'You are a professional email assistant specializing in crafting compelling and structured business emails.'}, {'role': 'user', 'content': \"Generate a professional email with a compelling subject for GreenBuild Solutions team in a company in GreenBuild Solutions, a company in the Architecture & Construction industry.\\n\\nThe company has expressed a need for VR-based architectural visualization tools, and we offer the following relevant products:\\n\\n- VR Architect Pro: A high-end VR software for immersive architectural visualization.\\n- ImmersiBuild VR: An advanced VR platform for architects to visualize and modify structures in real-time.\\n- MediVR Sim: A VR-based medical training simulator for healthcare professionals.\\n\\nThe email should include:\\n- A relevant subject line\\n- A personalized greeting\\n- A concise, engaging introduction\\n- A brief mention of the relevant products\\n- A clear call to action for scheduling a discussion or demo\\n- A professional closing with the sender's name (Mahmoud Saad) and company (M.S)\\n\\nRespond with only the email subject and body.\"}, {'role': 'assistant', 'content': \"Subject: Unlock Immersive Architectural Visualization with GreenBuild Solutions\\n\\nDear GreenBuild Solutions Team,\\n\\nAs we continue to push the boundaries of innovative architectural solutions, I wanted to highlight the vast potential of Virtual Reality (VR) in transforming the way architects and designers visualize and interact with their creations. Our team at GreenBuild Solutions has been working closely with industry leaders to develop cutting-edge VR-based architectural visualization tools that can elevate your design process and client engagement.\\n\\nWe'd like to introduce you to our flagship products: VR Architect Pro, ImmersiBuild VR, and MediVR Sim. These tools offer unparalleled levels of immersion, flexibility, and precision, allowing architects to visualize and modify structures in real-time, and even train healthcare professionals in a realistic and engaging environment.\\n\\nI'd love to schedule a discussion to explore how our solutions can address your specific needs and goals. Please let me know a convenient time for a demo, and I'll make sure to arrange it for you.\\n\\nBest regards,\\nMahmoud Saad\\nM.S\"}]\n",
            "Unlock Immersive Architectural Visualization with GreenBuild Solutions\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'role': 'system', 'content': 'You are a professional email assistant specializing in crafting compelling and structured business emails.'}, {'role': 'user', 'content': \"Generate a professional email with a compelling subject for MediTech Innovations team in a company in MediTech Innovations, a company in the Healthcare industry.\\n\\nThe company has expressed a need for VR-based medical training simulators, and we offer the following relevant products:\\n\\n- MediVR Sim: A VR-based medical training simulator for healthcare professionals.\\n- MediSim XR: A next-generation extended reality (XR) medical training simulator for surgery and\\n- EduVR Class: A VR-based virtual classroom solution for interactive online education.\\n\\nThe email should include:\\n- A relevant subject line\\n- A personalized greeting\\n- A concise, engaging introduction\\n- A brief mention of the relevant products\\n- A clear call to action for scheduling a discussion or demo\\n- A professional closing with the sender's name (Mahmoud Saad) and company (M.S)\\n\\nRespond with only the email subject and body.\"}, {'role': 'assistant', 'content': \"Subject: Revolutionize Medical Training with Our Innovative VR Solutions\\n\\nDear MediTech Innovations Team,\\n\\nWe are thrilled to learn about your company's interest in enhancing medical training with cutting-edge technology. Our team at M.S has been at the forefront of developing immersive VR-based medical training simulators that can revolutionize the way healthcare professionals learn and practice.\\n\\nOur portfolio includes MediVR Sim, a comprehensive VR-based medical training simulator; MediSim XR, a next-generation extended reality (XR) medical training simulator for surgery; and EduVR Class, a VR-based virtual classroom solution for interactive online education. These innovative solutions can help you bridge the gap between theoretical knowledge and practical application, ultimately leading to better patient outcomes.\\n\\nWe would love to schedule a discussion or demo to explore how our products can cater to your specific needs and enhance your medical training programs. Please let us know a convenient time and date, and we will make sure to schedule it accordingly.\\n\\nThank you for considering our innovative solutions. We look forward to hearing from you soon.\\n\\nBest regards,\\nMahmoud Saad\\nM.S\"}]\n",
            "Revolutionize Medical Training with Our Innovative VR Solutions\n",
            "Sent Emails:\n",
            "(1, 'GreenBuild Solutions', 'mahmoud.saad.mahmoud.11@gmail.com', 'Unlock Immersive Architectural Visualization with GreenBuild Solutions', \"Dear GreenBuild Solutions Team,\\n\\nAs we continue to push the boundaries of innovative architectural solutions, I wanted to highlight the vast potential of Virtual Reality (VR) in transforming the way architects and designers visualize and interact with their creations. Our team at GreenBuild Solutions has been working closely with industry leaders to develop cutting-edge VR-based architectural visualization tools that can elevate your design process and client engagement.\\n\\nWe'd like to introduce you to our flagship products: VR Architect Pro, ImmersiBuild VR, and MediVR Sim. These tools offer unparalleled levels of immersion, flexibility, and precision, allowing architects to visualize and modify structures in real-time, and even train healthcare professionals in a realistic and engaging environment.\\n\\nI'd love to schedule a discussion to explore how our solutions can address your specific needs and goals. Please let me know a convenient time for a demo, and I'll make sure to arrange it for you.\\n\\nBest regards,\\nMahmoud Saad\\nM.S\", 'sent', '2025-02-09 08:30:55')\n",
            "(2, 'MediTech Innovations', 'mahm0udsa3d404@gmail.com', 'Revolutionize Medical Training with Our Innovative VR Solutions', \"Dear MediTech Innovations Team,\\n\\nWe are thrilled to learn about your company's interest in enhancing medical training with cutting-edge technology. Our team at M.S has been at the forefront of developing immersive VR-based medical training simulators that can revolutionize the way healthcare professionals learn and practice.\\n\\nOur portfolio includes MediVR Sim, a comprehensive VR-based medical training simulator; MediSim XR, a next-generation extended reality (XR) medical training simulator for surgery; and EduVR Class, a VR-based virtual classroom solution for interactive online education. These innovative solutions can help you bridge the gap between theoretical knowledge and practical application, ultimately leading to better patient outcomes.\\n\\nWe would love to schedule a discussion or demo to explore how our products can cater to your specific needs and enhance your medical training programs. Please let us know a convenient time and date, and we will make sure to schedule it accordingly.\\n\\nThank you for considering our innovative solutions. We look forward to hearing from you soon.\\n\\nBest regards,\\nMahmoud Saad\\nM.S\", 'sent', '2025-02-09 08:31:07')\n",
            "\n",
            "Received Emails:\n"
          ]
        }
      ],
      "source": [
        "import smtplib\n",
        "import os\n",
        "import pandas as pd\n",
        "import PyPDF2\n",
        "import torch\n",
        "from email import encoders\n",
        "from email.mime.base import MIMEBase\n",
        "from email.mime.multipart import MIMEMultipart\n",
        "from email.mime.text import MIMEText\n",
        "from transformers import pipeline\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import numpy as np\n",
        "import re\n",
        "import sqlite3\n",
        "\n",
        "# Gmail SMTP Configuration\n",
        "SMTP_SERVER = \"smtp.gmail.com\"\n",
        "SMTP_PORT = 465\n",
        "\n",
        "# Your Gmail Credentials (Use App Password, NOT Gmail password)\n",
        "sender_email = \"mahmouds3d1.1@gmail.com\"\n",
        "app_password = \"nrum vhah zkxl uuqh\"\n",
        "\n",
        "# File paths\n",
        "csv_file = \"/content/VR_and_Software_Companies_2.csv\"\n",
        "pdf_file = \"/content/detailed_product_catalog.pdf\"\n",
        "\n",
        "model = pipeline(\"text-generation\", model=\"meta-llama/Llama-3.2-3B-Instruct\", torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
        "\n",
        "sender_name = \"Mahmoud Saad\"\n",
        "sender_company = \"M.S\"\n",
        "\n",
        "# Read CSV containing company details\n",
        "companies_df = pd.read_csv(csv_file)\n",
        "\n",
        "# Connect to SQLite database (or create it if it doesn't exist)\n",
        "conn = sqlite3.connect('emails.db')\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Create a table to store emails\n",
        "cursor.execute('''\n",
        "CREATE TABLE IF NOT EXISTS emails (\n",
        "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    company_name TEXT NOT NULL,\n",
        "    email TEXT NOT NULL,\n",
        "    subject TEXT NOT NULL,\n",
        "    message TEXT NOT NULL,\n",
        "    category TEXT NOT NULL,  -- 'sent' or 'received'\n",
        "    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP\n",
        ")\n",
        "''')\n",
        "\n",
        "conn.commit()\n",
        "\n",
        "def extract_subject_and_body(conversation):\n",
        "    # Find the assistant's response\n",
        "    assistant_response = next((item for item in conversation if item.get('role') == 'assistant'), None)\n",
        "\n",
        "    if assistant_response:\n",
        "        response_text = assistant_response.get('content', '')\n",
        "    else:\n",
        "        return \"No Subject\", \"No Content\"\n",
        "\n",
        "    # Extract subject\n",
        "    subject_match = re.search(r\"Subject:\\s*(.*)\", response_text, re.IGNORECASE)\n",
        "    subject = subject_match.group(1).strip() if subject_match else \"No Subject\"\n",
        "\n",
        "    # Extract body: captures everything after the first \"Subject\" line\n",
        "    body_match = re.search(r\"Subject:.*?\\n+(.*)\", response_text, re.DOTALL)\n",
        "    email_body = body_match.group(1).strip() if body_match else response_text.strip()\n",
        "\n",
        "    return subject, email_body\n",
        "\n",
        "# Extract product information from PDF\n",
        "def extract_products_from_pdf(pdf_path):\n",
        "    products = []\n",
        "    with open(pdf_path, \"rb\") as file:\n",
        "        reader = PyPDF2.PdfReader(file)\n",
        "        text = \"\\n\".join([page.extract_text() for page in reader.pages if page.extract_text()])\n",
        "\n",
        "        lines = text.split(\"\\n\")\n",
        "        for i in range(len(lines)):\n",
        "            if \"Product:\" in lines[i]:\n",
        "                product_name = lines[i].replace(\"Product: \", \"\").strip()\n",
        "                industry = lines[i + 1].replace(\"Industry: \", \"\").strip()\n",
        "                description = lines[i + 2].replace(\"Description: \", \"\").strip()\n",
        "                specifications = lines[i + 3].replace(\"Specifications: \", \"\").strip()\n",
        "                case_study = lines[i + 4].replace(\"Case Study: \", \"\").strip()\n",
        "                compliance = lines[i + 5].replace(\"Compliance: \", \"\").strip()\n",
        "                products.append({\n",
        "                    \"Product Name\": product_name,\n",
        "                    \"Industry\": industry,\n",
        "                    \"Description\": description,\n",
        "                    \"Specifications\": specifications,\n",
        "                    \"Case Study\": case_study,\n",
        "                    \"Compliance\": compliance\n",
        "                })\n",
        "    return products\n",
        "\n",
        "product_list = extract_products_from_pdf(pdf_file)\n",
        "\n",
        "# Load Sentence Transformer model for embeddings\n",
        "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Create FAISS index for product descriptions\n",
        "def create_faiss_index(products):\n",
        "    descriptions = [p['Description'] for p in products]\n",
        "    embeddings = embedder.encode(descriptions)\n",
        "    index = faiss.IndexFlatL2(embeddings.shape[1])\n",
        "    index.add(np.array(embeddings))\n",
        "    return index, descriptions\n",
        "\n",
        "faiss_index, product_descriptions = create_faiss_index(product_list)\n",
        "\n",
        "# Function to find relevant products using embeddings\n",
        "def find_relevant_products(need, top_k=3):\n",
        "    need_embedding = embedder.encode([need])\n",
        "    distances, indices = faiss_index.search(np.array(need_embedding), top_k)\n",
        "    return [product_list[i] for i in indices[0]]\n",
        "\n",
        "# Function to generate customized email and subject using LLM\n",
        "def generate_email_and_subject(company_name, industry, need):\n",
        "    relevant_products = find_relevant_products(need)\n",
        "    product_suggestions = \"\\n\".join([f\"- {p['Product Name']}: {p['Description']}\" for p in relevant_products])\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a professional email assistant specializing in crafting compelling and structured business emails.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"Generate a professional email with a compelling subject for {company_name} team in a company in {company_name}, a company in the {industry} industry.\\n\\nThe company has expressed a need for {need}, and we offer the following relevant products:\\n\\n{product_suggestions}\\n\\nThe email should include:\\n- A relevant subject line\\n- A personalized greeting\\n- A concise, engaging introduction\\n- A brief mention of the relevant products\\n- A clear call to action for scheduling a discussion or demo\\n- A professional closing with the sender's name ({sender_name}) and company ({sender_company})\\n\\nRespond with only the email subject and body.\"}\n",
        "    ]\n",
        "\n",
        "    output = model(messages, max_new_tokens=512)[0]['generated_text']\n",
        "    print(output)\n",
        "    subject, email_body = extract_subject_and_body(output)\n",
        "    print(subject)\n",
        "    return subject, email_body\n",
        "\n",
        "# Function to send email and log it\n",
        "def send_email(to_email, company_name, industry, need):\n",
        "    try:\n",
        "        subject, email_body = generate_email_and_subject(company_name, industry, need)\n",
        "\n",
        "        message = MIMEMultipart()\n",
        "        message[\"From\"] = sender_email\n",
        "        message[\"To\"] = to_email\n",
        "        message[\"Subject\"] = subject\n",
        "        message.attach(MIMEText(email_body, \"plain\"))\n",
        "\n",
        "        with open(pdf_file, \"rb\") as attachment:\n",
        "            part = MIMEBase(\"application\", \"octet-stream\")\n",
        "            part.set_payload(attachment.read())\n",
        "        encoders.encode_base64(part)\n",
        "        part.add_header(\"Content-Disposition\", f\"attachment; filename={os.path.basename(pdf_file)}\")\n",
        "        message.attach(part)\n",
        "\n",
        "        with smtplib.SMTP_SSL(SMTP_SERVER, SMTP_PORT) as server:\n",
        "            server.login(sender_email, app_password)\n",
        "            server.sendmail(sender_email, to_email, message.as_string())\n",
        "\n",
        "        # Log the sent email in the SQLite database\n",
        "        cursor.execute('''\n",
        "        INSERT INTO emails (company_name, email, subject, message, category)\n",
        "        VALUES (?, ?, ?, ?, ?)\n",
        "        ''', (company_name, to_email, subject, email_body, 'sent'))\n",
        "\n",
        "        conn.commit()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error sending email to {company_name} ({to_email}): {e}\")\n",
        "\n",
        "# Function to store received emails\n",
        "def store_received_email(company_name, email, subject, message):\n",
        "    cursor.execute('''\n",
        "    INSERT INTO emails (company_name, email, subject, message, category)\n",
        "    VALUES (?, ?, ?, ?, ?)\n",
        "    ''', (company_name, email, subject, message, 'received'))\n",
        "\n",
        "    conn.commit()\n",
        "\n",
        "# Function to retrieve emails\n",
        "def get_emails(category=None):\n",
        "    if category:\n",
        "        cursor.execute('SELECT * FROM emails WHERE category = ?', (category,))\n",
        "    else:\n",
        "        cursor.execute('SELECT * FROM emails')\n",
        "\n",
        "    return cursor.fetchall()\n",
        "\n",
        "# Send emails to all companies\n",
        "for _, row in companies_df.iterrows():\n",
        "    send_email(row[\"Email\"], row[\"Company Name\"], row[\"Industry\"], row[\"Need\"])\n",
        "\n",
        "# Example usage:\n",
        "sent_emails = get_emails(category='sent')\n",
        "received_emails = get_emails(category='received')\n",
        "\n",
        "print(\"Sent Emails:\")\n",
        "for email in sent_emails:\n",
        "    print(email)\n",
        "\n",
        "print(\"\\nReceived Emails:\")\n",
        "for email in received_emails:\n",
        "    print(email)\n",
        "\n",
        "# Close the database connection\n",
        "conn.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "affedaf0"
      },
      "source": [
        "\n",
        "### 📧 **Script 1: `event_driven_emails.py`**  \n",
        "**Purpose:**  \n",
        "This script continuously monitors your Gmail inbox for unread emails. It handles the queuing and processing of these emails using an SQLite database and external scripts.  \n",
        "\n",
        "#### 🗂️ **Key Components:**  \n",
        "1. **Imports & Setup:**  \n",
        "   - Libraries like `imaplib`, `email`, `sqlite3`, `subprocess`, and `psutil` are used for email handling, database interaction, and process management.  \n",
        "   - Email credentials and paths for the database, queue, and process scripts are defined.  \n",
        "\n",
        "2. **Database Initialization:**  \n",
        "   - Creates an `emails` table in SQLite if it doesn't exist to store email metadata (company, subject, message, etc.).  \n",
        "\n",
        "3. **Email Monitoring Functions:**  \n",
        "   - **`fetch_unread_emails()`**: Connects to Gmail, fetches unread emails, extracts relevant information (sender, subject, body), and stores them in the database if the sender exists.  \n",
        "   - **`mark_email_as_read()`**: Marks processed emails as read.  \n",
        "\n",
        "4. **Queue Handling:**  \n",
        "   - **`add_to_queue()`**: Adds new emails to a JSON-based queue if the processing script is busy.  \n",
        "   - **`process_queue()`**: Processes queued emails once the system is free.  \n",
        "\n",
        "5. **Integration with External Script:**  \n",
        "   - **`send_emails_to_script()`**: Forwards emails to `response.py` for classification and response generation.  \n",
        "\n",
        "6. **Continuous Loop:**  \n",
        "   - Runs every 60 seconds to check for new emails, manage the queue, and trigger processing tasks.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQ23W-nLF-mN",
        "outputId": "309ad9a0-1e2c-48c9-a2ab-22277cd19e03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting event_driven_emails.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile event_driven_emails.py\n",
        "import imaplib\n",
        "import email\n",
        "import time\n",
        "import sqlite3\n",
        "import subprocess\n",
        "import json\n",
        "from email.header import decode_header\n",
        "import psutil  # To check if the external script is running\n",
        "import time\n",
        "import random\n",
        "import smtplib\n",
        "import os\n",
        "import sqlite3\n",
        "import PyPDF2\n",
        "import numpy as np\n",
        "import faiss\n",
        "import re\n",
        "from email.mime.multipart import MIMEMultipart\n",
        "from email.mime.text import MIMEText\n",
        "\n",
        "\n",
        "# Email credentials\n",
        "EMAIL_USER = \"mahmouds3d1.1@gmail.com\"\n",
        "EMAIL_PASSWORD = \"nrum vhah zkxl uuqh\"  # Use an app password if required\n",
        "IMAP_SERVER = \"imap.gmail.com\"\n",
        "\n",
        "# SQLite database path\n",
        "SQLITE_DB = \"/content/emails.db\"\n",
        "TEMP_FILE = \"/content/temp_emails.json\"  # Temporary file for email list\n",
        "QUEUE_FILE = \"/content/email_queue.json\"   # ✅ Queue file for pending emails\n",
        "PROCESS_SCRIPT = \"/content/response.py\"  # External script to handle emails\n",
        "\n",
        "# Connect to SQLite database\n",
        "conn = sqlite3.connect(SQLITE_DB)\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Create emails table if it doesn't exist\n",
        "cursor.execute('''\n",
        "CREATE TABLE IF NOT EXISTS emails (\n",
        "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    company_name TEXT NOT NULL,\n",
        "    email TEXT NOT NULL,\n",
        "    subject TEXT NOT NULL,\n",
        "    message TEXT NOT NULL,\n",
        "    category TEXT NOT NULL,  -- 'sent' or 'received'\n",
        "    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP\n",
        ")\n",
        "''')\n",
        "conn.commit()\n",
        "\n",
        "# ✅ Check if the response.py script is running\n",
        "def is_process_running(script_name):\n",
        "    for proc in psutil.process_iter(['pid', 'name', 'cmdline']):\n",
        "        if script_name in proc.info['cmdline']:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "# ✅ Add emails to the queue\n",
        "def add_to_queue(email_list):\n",
        "    with open(QUEUE_FILE, \"r\") as file:\n",
        "        queue = json.load(file)\n",
        "\n",
        "    queue.extend(email_list)\n",
        "\n",
        "    with open(QUEUE_FILE, \"w\") as file:\n",
        "        json.dump(queue, file)\n",
        "\n",
        "    print(f\"Queued {len(email_list)} emails.\")\n",
        "\n",
        "# ✅ Process emails from the queue\n",
        "def process_queue():\n",
        "    with open(QUEUE_FILE, \"r\") as file:\n",
        "        queued_emails = json.load(file)\n",
        "\n",
        "    if queued_emails:\n",
        "        print(f\"Processing {len(queued_emails)} queued emails...\")\n",
        "        send_emails_to_script(queued_emails)\n",
        "\n",
        "        # Clear the queue after processing\n",
        "        with open(QUEUE_FILE, \"w\") as file:\n",
        "            json.dump([], file)\n",
        "\n",
        "\n",
        "def mark_email_as_read(mail, email_id):\n",
        "    \"\"\"Mark the email as read.\"\"\"\n",
        "    mail.store(email_id, '+FLAGS', '\\\\Seen')\n",
        "\n",
        "def fetch_unread_emails():\n",
        "    \"\"\"Fetch unread emails from the inbox.\"\"\"\n",
        "    try:\n",
        "        mail = imaplib.IMAP4_SSL(IMAP_SERVER)\n",
        "        mail.login(EMAIL_USER, EMAIL_PASSWORD)\n",
        "        mail.select(\"inbox\")  # Select inbox\n",
        "\n",
        "        # Search for unread emails\n",
        "        status, messages = mail.search(None, \"UNSEEN\")\n",
        "        email_ids = messages[0].split()\n",
        "\n",
        "        if not email_ids:\n",
        "            print(\"No new emails found.\")\n",
        "            mail.logout()\n",
        "            return []\n",
        "\n",
        "        EMAIL_LIST = []  # Store extracted email addresses\n",
        "        for num in reversed(email_ids):  # Process from latest to oldest\n",
        "            status, data = mail.fetch(num, \"(RFC822)\")\n",
        "            for response_part in data:\n",
        "                if isinstance(response_part, tuple):\n",
        "                    msg = email.message_from_bytes(response_part[1])\n",
        "\n",
        "                    # Decode email subject\n",
        "                    subject, encoding = decode_header(msg[\"Subject\"])[0]\n",
        "                    if isinstance(subject, bytes):\n",
        "                        subject = subject.decode(encoding if encoding else 'utf-8')\n",
        "\n",
        "                    # Get sender email\n",
        "                    from_email = msg.get(\"From\")\n",
        "                    from_email = from_email.split(\"<\")[-1].strip(\">\")  # Extract clean email\n",
        "                    EMAIL_LIST.append(from_email)\n",
        "\n",
        "                    # Get email body\n",
        "                    body = \"\"\n",
        "                    for part in msg.walk():\n",
        "                        content_type = part.get_content_type()\n",
        "                        content_disposition = str(part.get(\"Content-Disposition\") or \"\")\n",
        "\n",
        "                        if content_type == \"text/plain\" and \"attachment\" not in content_disposition:\n",
        "                            body = part.get_payload(decode=True).decode(errors=\"ignore\")\n",
        "                            break  # Stop after getting the plain text part\n",
        "\n",
        "                    if not body:\n",
        "                        continue  # Skip if no body found\n",
        "                    print(f\"\\nNew Email from {from_email}: {subject}\")\n",
        "\n",
        "                    # ✅ Check if the sender exists in the contacts table\n",
        "                    cursor.execute('SELECT * FROM emails WHERE email = ?', (from_email,))\n",
        "                    contact = cursor.fetchone()\n",
        "\n",
        "                    if contact:  # ✅ Insert only if the sender exists in the database\n",
        "                        company_name = contact[1] if len(contact) > 1 else \"Unknown Company\"\n",
        "\n",
        "                        # ✅ Insert the received email into the SQLite database\n",
        "                        cursor.execute('''\n",
        "                            INSERT INTO emails (company_name, email, subject, message, category)\n",
        "                            VALUES (?, ?, ?, ?, ?)\n",
        "                        ''', (company_name, from_email, subject, body, 'received'))\n",
        "                        conn.commit()\n",
        "\n",
        "                        # ✅ Mark email as read only for known senders\n",
        "                        mark_email_as_read(mail, num)\n",
        "                    else:\n",
        "                        print(f\"Skipped email from unknown sender: {from_email}\")\n",
        "\n",
        "        mail.logout()\n",
        "        return EMAIL_LIST  # Return the list of emails\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Error:\", e)\n",
        "        return []\n",
        "\n",
        "def send_emails_to_script(email_list):\n",
        "    \"\"\"Pass the list of emails to another script (process_emails.py).\"\"\"\n",
        "    if email_list:\n",
        "        print(f\"Passing {len(email_list)} emails to {PROCESS_SCRIPT}...\")\n",
        "\n",
        "        # Save email list to a temporary file\n",
        "        with open(TEMP_FILE, \"w\") as file:\n",
        "            json.dump(email_list, file)\n",
        "\n",
        "        # Run the external script with the file path as an argument\n",
        "        subprocess.Popen([\"python\", PROCESS_SCRIPT, TEMP_FILE])\n",
        "\n",
        "# Ensure the queue file exists\n",
        "if not os.path.exists(QUEUE_FILE):\n",
        "    with open(QUEUE_FILE, \"w\") as file:\n",
        "        json.dump([], file)  # Initialize with an empty list\n",
        "\n",
        "\n",
        "# Run the script continuously every 60 seconds\n",
        "while True:\n",
        "    emails = fetch_unread_emails()\n",
        "\n",
        "    # Check the size of the email queue\n",
        "    with open(QUEUE_FILE, \"r\") as file:\n",
        "        queue_size = len(json.load(file))\n",
        "\n",
        "    if emails or queue_size != 0:\n",
        "        if is_process_running(PROCESS_SCRIPT):\n",
        "            # Add new emails to the queue if the process is running\n",
        "            add_to_queue(emails)\n",
        "        elif emails and queue_size != 0:\n",
        "            # Process queued emails first, then send new emails\n",
        "            process_queue()\n",
        "            send_emails_to_script(emails)\n",
        "        elif emails:\n",
        "            # Send new emails directly if there's no queue\n",
        "            send_emails_to_script(emails)\n",
        "        elif queue_size != 0:\n",
        "            # Process queued emails if no new emails are found\n",
        "            process_queue()\n",
        "    time.sleep(60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6be25dc1"
      },
      "source": [
        "\n",
        "### 🤖 **Script 2: `response.py`**  \n",
        "**Purpose:**  \n",
        "This script processes the emails passed from `event_driven_emails.py`. It classifies responses using a zero-shot classification model and generates replies when needed.  \n",
        "\n",
        "#### 🗂️ **Key Components:**  \n",
        "1. **Imports & Setup:**  \n",
        "   - Uses libraries like `transformers`, `sqlite3`, `faiss`, and `PyPDF2` for NLP tasks, database access, and working with product catalogs.  \n",
        "   - Connects to the same SQLite database and loads the pending emails from a temporary JSON file.  \n",
        "\n",
        "2. **Model Initialization:**  \n",
        "   - **Zero-Shot Classification:** Uses Facebook's `BART-large-mnli` to classify email responses into categories:  \n",
        "     - **\"Not interested\"**  \n",
        "     - **\"Need more details\"**  \n",
        "     - **\"Want to make a meeting\"**  \n",
        "   - **LLM for Response Generation:** Uses Meta’s LLaMA model to generate detailed responses when needed.  \n",
        "\n",
        "3. **Email Classification & Response:**  \n",
        "   - **`classify_email()`**: Determines the intent of the latest email response.  \n",
        "   - **`get_latest_response()` & `get_full_conversation()`**: Retrieve conversation history from the database to maintain context in replies.  \n",
        "   - **`extract_subject_and_body()`**: Parses the generated response to extract the subject and body for the reply.  \n",
        "\n",
        "4. **Sending Replies:**  \n",
        "   - Composes and sends emails when the classification result is **\"Need more details\"**.  \n",
        "   - For **\"Want to make a meeting\"**, it forwards the request to HR.  \n",
        "   - **\"Not interested\"** responses are ignored.  \n",
        "\n",
        "---\n",
        "\n",
        "### 🔄 **How They Work Together:**  \n",
        "1. **Email Received →** `event_driven_emails.py` detects it.  \n",
        "2. **Processing →** If busy, the email is queued; otherwise, it's sent to `response.py`.  \n",
        "3. **Classification →** `response.py` determines the email type.  \n",
        "4. **Action →** Sends an automated reply, forwards to HR, or ignores based on the classification.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCs66HGTNko8",
        "outputId": "b022e95f-9a07-406c-a0a4-04b2bd7b1ee4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting response.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile response.py\n",
        "import smtplib\n",
        "import os\n",
        "import json\n",
        "import sqlite3\n",
        "import PyPDF2\n",
        "import numpy as np\n",
        "import faiss\n",
        "import re\n",
        "from email.mime.multipart import MIMEMultipart\n",
        "from email.mime.text import MIMEText\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import psutil  # To check if the external script is running\n",
        "import time\n",
        "import random\n",
        "print(\"Hi\")\n",
        "# File paths and email details\n",
        "SQLITE_DB = \"/content/emails.db\"\n",
        "pdf_file = \"/content/detailed_product_catalog.pdf\"\n",
        "json_file = \"/content/temp_emails.json\"\n",
        "sender_email = \"mahmouds3d1.1@gmail.com\"\n",
        "app_password = \"nrum vhah zkxl uuqh\"\n",
        "sender_name = \"Mahmoud Saad\"\n",
        "sender_company = \"M.S\"\n",
        "\n",
        "# Load email list from JSON file\n",
        "with open(json_file, \"r\") as file:\n",
        "    email_list = json.load(file)\n",
        "print(email_list)\n",
        "# Connect to SQLite database\n",
        "conn = sqlite3.connect(SQLITE_DB)\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Load BART MNLI zero-shot classification pipeline\n",
        "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
        "\n",
        "# Load Llama model\n",
        "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "# Classification categories\n",
        "categories = [\"Not interested\", \"Need more details\", \"Want to make a meeting\"]\n",
        "\n",
        "def classify_email(response):\n",
        "    if not response or response.lower() == \"no response\":\n",
        "        return \"No Response\"\n",
        "    result = classifier(response, candidate_labels=categories)\n",
        "    return result['labels'][0]\n",
        "\n",
        "def get_latest_response(email):\n",
        "    \"\"\"Retrieve the latest response for a given email.\"\"\"\n",
        "    cursor.execute('''\n",
        "    SELECT message FROM emails\n",
        "    WHERE email = ? AND category = 'received'\n",
        "    ORDER BY timestamp DESC\n",
        "    LIMIT 1\n",
        "    ''', (email,))\n",
        "    result = cursor.fetchone()\n",
        "    return result[0] if result else None\n",
        "\n",
        "def get_full_conversation(email):\n",
        "    \"\"\"Retrieve the full conversation history for a given email.\"\"\"\n",
        "    cursor.execute('''\n",
        "    SELECT message, category FROM emails\n",
        "    WHERE email = ?\n",
        "    ORDER BY timestamp ASC\n",
        "    ''', (email,))\n",
        "    results = cursor.fetchall()\n",
        "    conversation = []\n",
        "    for message, category in results:\n",
        "        conversation.append(f\"{category}: {message}\")\n",
        "    return \"\\n\".join(conversation)\n",
        "\n",
        "def extract_subject_and_body(conversation):\n",
        "    # Find the assistant's response\n",
        "    assistant_response = next((item for item in conversation if item.get('role') == 'assistant'), None)\n",
        "\n",
        "    if assistant_response:\n",
        "        response_text = assistant_response.get('content', '')\n",
        "    else:\n",
        "        return \"No Subject\", \"No Content\"\n",
        "\n",
        "    # Extract subject\n",
        "    subject_match = re.search(r\"Subject:\\s*(.*)\", response_text, re.IGNORECASE)\n",
        "    subject = subject_match.group(1).strip() if subject_match else \"No Subject\"\n",
        "\n",
        "    # Extract body: captures everything after the first \"Subject\" line\n",
        "    body_match = re.search(r\"Subject:.*?\\n+(.*)\", response_text, re.DOTALL)\n",
        "    email_body = body_match.group(1).strip() if body_match else response_text.strip()\n",
        "\n",
        "    return subject, email_body\n",
        "\n",
        "def extract_products_from_pdf(pdf_path):\n",
        "    products = []\n",
        "    with open(pdf_path, \"rb\") as file:\n",
        "        reader = PyPDF2.PdfReader(file)\n",
        "        text = \"\\n\".join([page.extract_text() for page in reader.pages if page.extract_text()])\n",
        "\n",
        "        lines = text.split(\"\\n\")\n",
        "        for i in range(len(lines)):\n",
        "            if \"Product:\" in lines[i]:\n",
        "                product_name = lines[i].replace(\"Product: \", \"\").strip()\n",
        "                industry = lines[i + 1].replace(\"Industry: \", \"\").strip()\n",
        "                description = lines[i + 2].replace(\"Description: \", \"\").strip()\n",
        "                specifications = lines[i + 3].replace(\"Specifications: \", \"\").strip()\n",
        "                case_study = lines[i + 4].replace(\"Case Study: \", \"\").strip()\n",
        "                compliance = lines[i + 5].replace(\"Compliance: \", \"\").strip()\n",
        "                products.append({\n",
        "                    \"Product Name\": product_name,\n",
        "                    \"Industry\": industry,\n",
        "                    \"Description\": description,\n",
        "                    \"Specifications\": specifications,\n",
        "                    \"Case Study\": case_study,\n",
        "                    \"Compliance\": compliance\n",
        "                })\n",
        "    return products\n",
        "\n",
        "product_list = extract_products_from_pdf(pdf_file)\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "def create_embeddings(products):\n",
        "    product_embeddings = []\n",
        "    for product in products:\n",
        "        text = f\"Product: {product['Product Name']}, Description: {product['Description']}, Specifications: {product['Specifications']}, Case Study: {product['Case Study']}, Compliance: {product['Compliance']}\"\n",
        "        embedding = embedding_model.encode(text)\n",
        "        product_embeddings.append(embedding)\n",
        "    return np.array(product_embeddings)\n",
        "\n",
        "product_embeddings = create_embeddings(product_list)\n",
        "index = faiss.IndexFlatL2(product_embeddings.shape[1])\n",
        "index.add(product_embeddings)\n",
        "\n",
        "def get_relevant_product(query):\n",
        "    query_embedding = embedding_model.encode([query])\n",
        "    query_embedding = np.array(query_embedding)\n",
        "    _, indices = index.search(query_embedding, k=1)\n",
        "    return product_list[indices[0][0]]\n",
        "\n",
        "def generate_email_and_subject(company_name, industry, conversation):\n",
        "    relevant_product = get_relevant_product(conversation)\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a professional email assistant who writes structured responses.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"Given the conversation history for {company_name} in the {industry} industry, generate a well-structured response.\\n\\nConversation:\\n{conversation}\\n\\nProduct Details:\\n- {relevant_product}\"}\n",
        "    ]\n",
        "    outputs = pipe(messages, max_new_tokens=512)\n",
        "    response_text = outputs[0][\"generated_text\"]\n",
        "    print(response_text)\n",
        "    subject, email_body = extract_subject_and_body(response_text)\n",
        "    return subject, email_body\n",
        "\n",
        "# Process each email in the list\n",
        "for email in email_list:\n",
        "    print(f\"Processing email from {email}...\")\n",
        "    latest_response = get_latest_response(email)\n",
        "    category = classify_email(latest_response)\n",
        "\n",
        "    if category == \"Need more details\":\n",
        "        conversation = get_full_conversation(email)\n",
        "        cursor.execute('''\n",
        "        SELECT company_name, subject FROM emails\n",
        "        WHERE email = ? AND category = 'received'\n",
        "        ORDER BY timestamp DESC\n",
        "        LIMIT 1\n",
        "        ''', (email,))\n",
        "        result = cursor.fetchone()\n",
        "        if result:\n",
        "            company_name, industry = result\n",
        "            subject, response = generate_email_and_subject(company_name, industry, conversation)\n",
        "\n",
        "            # Insert the sent email into the SQLite database\n",
        "            cursor.execute('''\n",
        "            INSERT INTO emails (company_name, email, subject, message, category)\n",
        "            VALUES (?, ?, ?, ?, ?)\n",
        "            ''', (company_name, email, subject, response, 'sent'))\n",
        "            conn.commit()\n",
        "\n",
        "            # Send the email\n",
        "            message = MIMEMultipart()\n",
        "            message[\"From\"], message[\"To\"], message[\"Subject\"] = sender_email, email, subject\n",
        "            message.attach(MIMEText(response, \"plain\"))\n",
        "\n",
        "            with smtplib.SMTP_SSL(\"smtp.gmail.com\", 465) as server:\n",
        "                server.login(sender_email, app_password)\n",
        "                server.sendmail(sender_email, email, message.as_string())\n",
        "\n",
        "            print(f\"Sent response to {email} for {company_name}\")\n",
        "\n",
        "conn.close()\n",
        "print(\"✅ Emails categorized, responses sent, and database updated.\")\n",
        "print(\"waiting\")\n",
        "time.sleep(random.randint(180, 200))\n",
        "print(\"finished\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bda98993"
      },
      "source": [
        "run the script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FN8siD4sN5GP",
        "outputId": "1ae33862-9ee2-49f2-b23f-31c2ed58bada"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No new emails found.\n",
            "\n",
            "New Email from mahmoud.saad.mahmoud.11@gmail.com: Re: VR-Based Architectural Visualization Tools\n",
            "Passing 1 emails to /content/response.py...\n",
            "2025-02-09 08:33:20.852205: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1739090000.914314    7229 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1739090000.933716    7229 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "Hi\n",
            "['mahmoud.saad.mahmoud.11@gmail.com']\n",
            "Device set to use cuda:0\n",
            "Loading checkpoint shards: 100% 2/2 [00:01<00:00,  1.85it/s]\n",
            "Device set to use cpu\n",
            "Processing email from mahmoud.saad.mahmoud.11@gmail.com...\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "\n",
            "New Email from mahm0udsa3d404@gmail.com: Re: VR-Based Medical Training Solutions Inquiry‏‏‏‏‏‏\n",
            "\n",
            "New Email from mahmoud.saad.mahmoud.11@gmail.com: Quick Follow-Up on VR Tools\n",
            "Queued 2 emails.\n",
            "No new emails found.\n",
            "Queued 0 emails.\n",
            "No new emails found.\n",
            "Queued 0 emails.\n",
            "No new emails found.\n",
            "Queued 0 emails.\n",
            "No new emails found.\n",
            "Queued 0 emails.\n",
            "No new emails found.\n",
            "Queued 0 emails.\n",
            "object address  : 0x7fc2a4f6cb20\n",
            "object refcount : 2\n",
            "object type     : 0x9d5ea0\n",
            "object type name: KeyboardInterrupt\n",
            "object repr     : KeyboardInterrupt()\n",
            "lost sys.stderr\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/response.py\", line 174, in <module>\n",
            "    subject, response = generate_email_and_subject(company_name, industry, conversation)\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/response.py\", line 151, in generate_email_and_subject\n",
            "    outputs = pipe(messages, max_new_tokens=512)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/pipelines/text_generation.py\", line 278, in __call__\n",
            "    return super().__call__(Chat(text_inputs), **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/pipelines/base.py\", line 1362, in __call__\n",
            "    return self.run_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/pipelines/base.py\", line 1369, in run_single\n",
            "    model_outputs = self.forward(model_inputs, **forward_params)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/pipelines/base.py\", line 1269, in forward\n",
            "    model_outputs = self._forward(model_inputs, **forward_params)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/pipelines/text_generation.py\", line 383, in _forward\n",
            "    generated_sequence = self.model.generate(input_ids=input_ids, attention_mask=attention_mask, **generate_kwargs)\n",
            "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\", line 2255, in generate\n",
            "    result = self._sample(\n",
            "             ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\", line 3257, in _sample\n",
            "    outputs = model_forward(**model_inputs, return_dict=True)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/llama/modeling_llama.py\", line 831, in forward\n",
            "    outputs = self.model(\n",
            "              ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/llama/modeling_llama.py\", line 589, in forward\n",
            "    layer_outputs = decoder_layer(\n",
            "                    ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/llama/modeling_llama.py\", line 348, in forward\n",
            "    hidden_states = self.mlp(hidden_states)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/llama/modeling_llama.py\", line 186, in forward\n",
            "    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
            "                                                                ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\", line 125, in forward\n",
            "    return F.linear(input, self.weight, self.bias)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!python event_driven_emails.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0afa991b"
      },
      "source": [
        "### Explanation for Cell 10\n",
        "This cell initializes or processes a specific part of the cold emailing system.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-HFdYJ9LhFm",
        "outputId": "6807d2bc-cc9b-4876-ab63-78dc957c4452"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sent Emails:\n",
            "(1, 'GreenBuild Solutions', 'mahmoud.saad.mahmoud.11@gmail.com', 'Revolutionize Architectural Visualization with GreenBuild Solutions', \"Dear GreenBuild Solutions Team,\\n\\nI wanted to personally reach out to you regarding your expressed interest in VR-based architectural visualization tools. Our team at GreenBuild Solutions has been at the forefront of innovation in this field, and I'd like to introduce you to our cutting-edge solutions that can elevate your architectural visualization capabilities.\\n\\nWe offer a range of products, including VR Architect Pro, ImmersiBuild VR, and MediVR Sim, each designed to provide unparalleled immersive experiences for architects and designers. Whether you're looking to enhance your design workflow, improve collaboration, or create stunning visualizations, our products can help.\\n\\nI'd love to schedule a discussion or demo to explore how our solutions can meet your specific needs. Please let me know a convenient time, and I'll ensure that our team is prepared to showcase the full potential of our products.\\n\\nBest regards,\\nMahmoud Saad\\nM.S\", 'sent', '2025-02-09 08:13:32')\n",
            "(2, 'MediTech Innovations', 'mahm0udsa3d404@gmail.com', 'Revolutionize Medical Training with Our VR-Based Solutions', \"Dear MediTech Innovations Team,\\n\\nWe're excited to explore how our cutting-edge VR-based medical training simulators can enhance your team's training and education. Our innovative products, including MediVR Sim, MediSim XR, and EduVR Class, have been designed to simulate real-world medical scenarios, providing healthcare professionals with a safe and immersive environment to practice and hone their skills.\\n\\nOur VR-based solutions offer a unique opportunity to revolutionize your medical training programs, allowing your team to:\\n\\n- Practice complex procedures in a realistic and controlled environment\\n- Enhance patient care and outcomes through improved clinical skills\\n- Reduce costs associated with traditional training methods\\n\\nWe'd love to schedule a discussion to learn more about your specific needs and demonstrate how our products can support your mission to provide exceptional patient care. Would you be available for a quick call or demo at your convenience?\\n\\nBest regards,\\nMahmoud Saad\\nM.S\", 'sent', '2025-02-09 08:13:44')\n",
            "(5, 'GreenBuild Solutions', 'mahmoud.saad.mahmoud.11@gmail.com', 'Re: VR-Based Architectural Visualization Tools', \"Dear GreenBuild Solutions Team,\\n\\nThank you for your prompt response and interest in our VR-based architectural visualization tools. I'm delighted to provide more information on our products, addressing your specific inquiries.\\n\\nOur visualization tools, including VR Architect Pro, ImmersiBuild VR, and MediVR Sim, are designed to provide unparalleled immersive experiences for architects and designers. Here's a brief overview of each product:\\n\\n- **VR Architect Pro**: Our flagship product, VR Architect Pro, is a high-end VR software for immersive architectural visualization. It supports BIM integration, cloud-based storage, and multi-user design collaboration. This enables seamless collaboration and reduces the need for physical models, resulting in significant time and cost savings.\\n\\n- **Interactivity and Detail**: Our tools offer a high level of interactivity, allowing users to manipulate and explore designs in a fully immersive environment. This enables architects and designers to gain a deeper understanding of their designs, identify potential issues, and make data-driven decisions.\\n\\n- **Real-Time Collaboration**: Our solutions support real-time collaboration, enabling multiple users to work together on a single project from anywhere in the world. This facilitates more efficient project management, reduces errors, and increases overall productivity.\\n\\n- **Compatibility**: Our tools are compatible with existing architectural software such as AutoCAD, Revit, and BIM platforms. This ensures a smooth integration with your existing workflows, reducing the need for significant changes or retraining.\\n\\nRegarding pricing structure and licensing options, we offer a flexible pricing model that caters to various project requirements. Our standard pricing includes:\\n\\n- **Monthly Subscription**: A flat monthly fee for access to our tools, with discounts available for annual commitments.\\n- **Customized Licensing**: We offer customized licensing options for large-scale projects or organizations with specific requirements.\\n- **Training and Support**: Our comprehensive training program ensures that you and your team are equipped to get the most out of our tools, while our dedicated support team is available to address any questions or concerns.\\n\\nI'd be happy to schedule a call or demo to discuss our solutions in more detail and explore how they can meet your specific needs. Please let me know a convenient time, and I'll ensure that our team is prepared to showcase the full potential of our products.\\n\\nThank you for your interest in GreenBuild Solutions. I look forward to hearing from you soon.\\n\\nBest regards,\\n\\nMahmoud Saad\\nM.S\", 'sent', '2025-02-09 08:16:21')\n",
            "(7, 'GreenBuild Solutions', 'mahmoud.saad.mahmoud.11@gmail.com', 'Re: Collaboration and Demo for VR Architectural Visualization Tools', \"Dear GreenBuild Solutions Team,\\n\\nThank you for your prompt and detailed response to our initial inquiry about our VR-based architectural visualization tools. We're excited to address your questions and provide more insights into our products.\\n\\nTo address your inquiries:\\n\\n1. **VR Architect Pro Compatibility**: Yes, VR Architect Pro is compatible with computers, and users can access our tools from a desktop or laptop. We also provide a mobile app for on-the-go access.\\n2. **VR Headset Integration**: Our tools are designed to work seamlessly with VR headsets, allowing users to fully immerse themselves in the visualization environment. We support a range of popular VR headsets, including Oculus and HTC Vive.\\n3. **Color and Black and White**: Our visualization tools are available in color, and we also offer a black and white mode for users who prefer a more traditional visualization experience.\\n4. **Power Requirements**: Our tools require a computer or mobile device with a compatible processor and graphics card to function. We do not require electricity to function, as our software is cloud-based and can be accessed from anywhere.\\n5. **Software Launch**: Our tools are designed to be user-friendly and intuitive. Users can launch the software by double-clicking on the icon or by searching for it in their computer's start menu.\\n\\nRegarding our products, we'd like to reiterate that our flagship product, VR Architect Pro, offers unparalleled immersive experiences for architects and designers. It supports BIM integration, cloud-based storage, and multi-user design collaboration, enabling seamless collaboration and reducing the need for physical models.\\n\\nWe'd also like to highlight our other products, including ImmersiBuild VR and MediVR Sim, which offer a range of features and functionalities tailored to specific needs and workflows.\\n\\nIn terms of pricing and licensing, we offer a flexible pricing model that caters to various project requirements. Our standard pricing includes:\\n\\n- **Monthly Subscription**: A flat monthly fee for access to our tools, with discounts available for annual commitments.\\n- **Customized Licensing**: We offer customized licensing options for large-scale projects or organizations with specific requirements.\\n- **Training and Support**: Our comprehensive training program ensures that you and your team are equipped to get the most out of our tools, while our dedicated support team is available to address any questions or concerns.\\n\\nWe'd be happy to schedule a call or demo to discuss our solutions in more detail and explore how they can meet your specific needs.\", 'sent', '2025-02-09 08:21:39')\n",
            "\n",
            "Received Emails:\n",
            "(3, 'GreenBuild Solutions', 'mahmoud.saad.mahmoud.11@gmail.com', 'Re: VR-Based Architectural Visualization Tools', \"Dear Mahmoud Saad,\\r\\n\\r\\nThank you for reaching out and for your interest in collaborating with\\r\\nGreenBuild Solutions. Your VR-based architectural visualization tools sound\\r\\npromising, and we'd love to explore how they might align with our current\\r\\nworkflows.\\r\\n\\r\\nCould you provide additional details on the following?\\r\\n\\r\\n   - The level of detail and interactivity your visualization tools offer\\r\\n   for architectural designs.\\r\\n   - How real-time collaboration functions within your solutions.\\r\\n   - Compatibility with existing architectural software such as AutoCAD,\\r\\n   Revit, or BIM platforms.\\r\\n   - Pricing structure and licensing options.\\r\\n\\r\\nWe’d appreciate more insights on these points before scheduling a call or\\r\\ndemo. Looking forward to your response.\\r\\n\\r\\nBest regards,\\r\\nGreenBuild Solutions Team\\r\\n\", 'received', '2025-02-09 08:14:52')\n",
            "(4, 'MediTech Innovations', 'mahm0udsa3d404@gmail.com', 'Re: VR-Based Medical Training Solutions Inquiry\\u200f\\u200f\\u200f\\u200f\\u200f', 'Dear Mahmoud Saad,\\r\\n\\r\\nThank you for reaching out and for introducing your innovative VR-based\\r\\nsolutions. We are very interested in exploring how these technologies could\\r\\nenhance our medical training programs.\\r\\n\\r\\nTo better understand the potential fit, could you provide more details on\\r\\nthe following?\\r\\n\\r\\n   - The specific medical fields or specialties your solutions best cater\\r\\n   to.\\r\\n   - Any case studies or success stories showcasing real-world applications.\\r\\n   - Integration possibilities with our existing training infrastructure.\\r\\n   - Pricing models and available customization options.\\r\\n\\r\\nWe’d love to set up a discussion once we have a clearer understanding of\\r\\nthese aspects. Looking forward to your insights.\\r\\n\\r\\nBest regards,\\r\\nMediTech Innovations Team\\r\\n', 'received', '2025-02-09 08:15:55')\n",
            "(6, 'GreenBuild Solutions', 'mahmoud.saad.mahmoud.11@gmail.com', 'Quick Follow-Up on VR Tools', 'Dear Mahmoud Saad,\\r\\n\\r\\nThank you for your detailed response. I just had a few quick questions:\\r\\n\\r\\n   1. Does VR Architect Pro work on computers?\\r\\n   2. Can users wear VR headsets while using your tools?\\r\\n   3. Is the software available in color, or just black and white?\\r\\n   4. Do the tools require electricity to function?\\r\\n   5. Is there a specific button to start the software, or does it open\\r\\n   automatically?\\r\\n\\r\\nI appreciate your time and look forward to your insights.\\r\\n\\r\\nBest regards,\\r\\nGreenBuild Solutions\\r\\n', 'received', '2025-02-09 08:19:09')\n"
          ]
        }
      ],
      "source": [
        "# # Function to retrieve emails\n",
        "# # Connect to SQLite database\n",
        "# SQLITE_DB = \"/content/emails.db\"\n",
        "# conn = sqlite3.connect(SQLITE_DB)\n",
        "# cursor = conn.cursor()\n",
        "\n",
        "# def get_emails(category=None):\n",
        "#     if category:\n",
        "#         cursor.execute('SELECT * FROM emails WHERE category = ?', (category,))\n",
        "#     else:\n",
        "#         cursor.execute('SELECT * FROM emails')\n",
        "\n",
        "#     return cursor.fetchall()\n",
        "\n",
        "# # Example usage:\n",
        "# sent_emails = get_emails(category='sent')\n",
        "# received_emails = get_emails(category='received')\n",
        "\n",
        "# print(\"Sent Emails:\")\n",
        "# for email in sent_emails:\n",
        "#     print(email)\n",
        "\n",
        "# print(\"\\nReceived Emails:\")\n",
        "# for email in received_emails:\n",
        "#     print(email)\n",
        "\n",
        "# # # ✅ Function to delete all received emails\n",
        "# # def delete_received_emails():\n",
        "# #     cursor.execute('DELETE FROM emails WHERE category = ?', ('received',))\n",
        "# #     cursor.execute('DELETE FROM emails WHERE category = ?', ('sent',))\n",
        "# #     conn.commit()\n",
        "# #     print(\"All received emails have been deleted.\")\n",
        "\n",
        "# # # ✅ Example usage:\n",
        "# # delete_received_emails()\n",
        "\n",
        "# # # ✅ To verify deletion\n",
        "# # received_emails = get_emails(category='received')\n",
        "# # print(\"\\nReceived Emails After Deletion:\")\n",
        "# # for email in received_emails:\n",
        "# #     print(email)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2e9b92b5"
      },
      "source": [
        "### Explanation for Cell 11\n",
        "This cell initializes or processes a specific part of the cold emailing system.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Di2n448o-i3x"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0a7651e388e045e0ac5064ea94dbee74": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "19ce64eac55c4cfda31064513df52cf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a2394a35229646ad92e45becff0aec7b",
              "IPY_MODEL_b9b2597e98d04cfab0c5e357c9d2c584",
              "IPY_MODEL_46fa54e7ac80485bb7453b25c8460f43"
            ],
            "layout": "IPY_MODEL_75d758fa70724ce6bfb912767179781b"
          }
        },
        "44eaac4008ea4c6c89b71417d91e3b4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46fa54e7ac80485bb7453b25c8460f43": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e841da1420d4b86a71b0aa739d339fb",
            "placeholder": "​",
            "style": "IPY_MODEL_44eaac4008ea4c6c89b71417d91e3b4d",
            "value": " 2/2 [00:23&lt;00:00, 11.22s/it]"
          }
        },
        "472405a3a9684085a3b66d1ca731bf72": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75d758fa70724ce6bfb912767179781b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e841da1420d4b86a71b0aa739d339fb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2394a35229646ad92e45becff0aec7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_472405a3a9684085a3b66d1ca731bf72",
            "placeholder": "​",
            "style": "IPY_MODEL_ca366d7080cd42189ef4df9135af637b",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "b9b2597e98d04cfab0c5e357c9d2c584": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bdf90ecc732a4ae5bc26c89eb821ad03",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0a7651e388e045e0ac5064ea94dbee74",
            "value": 2
          }
        },
        "bdf90ecc732a4ae5bc26c89eb821ad03": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca366d7080cd42189ef4df9135af637b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
